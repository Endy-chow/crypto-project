{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e7441a2",
   "metadata": {},
   "source": [
    "Transfer learning using cryptobert and roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28f08c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peter/.pyenv/versions/3.10.6/envs/crypto/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-03-09 10:57:39.264729: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-09 10:57:39.726396: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-09 10:57:39.726427: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-09 10:57:41.353746: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-09 10:57:41.354053: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-09 10:57:41.354061: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig, TextClassificationPipeline\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import softmax\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe56af4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4e60cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.20.0 in /home/peter/.pyenv/versions/3.10.6/envs/crypto/lib/python3.10/site-packages (3.20.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==3.20.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20081cbe",
   "metadata": {},
   "source": [
    "## Step 1 - Importing a sample of some Bitcoin Tweet Data to begin analysing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f8e4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42f73c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20230308 - test data from twitter api, from 20220624 to 20220812 \n",
    "# data = pd.read_csv('~/code/giadapi/crypto/raw_data/tweets_2022_reduced.csv')\n",
    "data = pd.read_csv('tweets_2022_reduced_preproc.csv')\n",
    "# 20230307 - test data from kaggle\n",
    "# data = pd.read_csv('~/code/giadapi/crypto/data/raw/bitcoin_tweets1000000.csv', nrows = 1000)\n",
    "# \"\\\\wsl.localhost\\Ubuntu\\home\\peter\\code\\giadapi\\crypto\\kaggle-tweets.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec789df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e950bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #only run it if the dataset is from Twitter API\n",
    "# data['text'] = data[['tweet']]\n",
    "# data['date'] = data[['created_at']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841439f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['text', 'datetime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4c0630",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'][103]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de89806",
   "metadata": {},
   "source": [
    "## Step 2 - Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f64e58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have changed this to remove more information\n",
    "\n",
    "def preprocess_2(text):\n",
    "    new_text = []\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    for t in text.split(\" \"):\n",
    "        t = '' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = '' if t.startswith('http') else t\n",
    "        \n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "sample_text = preprocess_2(data['text'][0])\n",
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e82154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the preprocess_2 to clean the data\n",
    "\n",
    "data['process_text'] = data.text\n",
    "# data['label_xlm'] = data.text\n",
    "# data['score_xlm'] = data.text\n",
    "# data['negative_xlm'] = data.text\n",
    "# data['neutral_xlm'] = data.text\n",
    "# data['positive_xlm'] = data.text\n",
    "\n",
    "data['label_bert'] = data.text\n",
    "# data['score_bert'] = data.text\n",
    "data['negative_bert'] = data.text\n",
    "data['neutral_bert'] = data.text\n",
    "data['positive_bert'] = data.text\n",
    "for i in range(len(data)):\n",
    "    data['process_text'][i] = preprocess_2(data['text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee90f146",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['datetime', 'process_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68017659",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('tweets_2022_reduced_preproc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95de5a6",
   "metadata": {},
   "source": [
    "## Step 3 - analyse the language and sentiments by pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfe8563",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pyenv local crypto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacfa720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1a - Use the xlm model - https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment?text=go+up\n",
    "\n",
    "# model_path_xlm = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "# sentiment_task_xlm = pipeline(\"sentiment-analysis\", model=model_path_xlm, tokenizer=model_path_xlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a1c576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_sent = sentiment_task_xlm(sample_text)\n",
    "# print(test_sent[0]['score'])\n",
    "# print(test_sent[0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1807c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1b - Use the xlm model, with full score\n",
    "# MODEL_xlm = f\"{model_path_xlm}\"\n",
    "# tokenizer_xlm = AutoTokenizer.from_pretrained(MODEL_xlm)\n",
    "# config_xlm = AutoConfig.from_pretrained(MODEL_xlm)\n",
    "\n",
    "# # PT\n",
    "# model_xlm = AutoModelForSequenceClassification.from_pretrained(MODEL_xlm)\n",
    "# # model_xlm.save_pretrained(MODEL_xlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ef746d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scores_xlm(x):\n",
    "#     encoded_input_xlm = tokenizer_xlm(x, return_tensors='pt')\n",
    "#     output_xlm = model_xlm(**encoded_input_xlm)\n",
    "#     scores_xlm = output_xlm[0][0].detach().numpy()\n",
    "#     scores_xlm = softmax(scores_xlm) #1st score is negative, 2nd score is netural, 3rd score is positive\n",
    "#     return scores_xlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45b9791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = scores_xlm(sample_text)\n",
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22af2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 2a - Use the CryptoBERT model - https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment?text=go+up\n",
    "\n",
    "model_path_bert = \"ElKulako/cryptobert\"\n",
    "sentiment_task_bert = pipeline(\"sentiment-analysis\", model=model_path_bert, tokenizer=model_path_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf1b27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent = sentiment_task_bert(sample_text)\n",
    "print(test_sent[0]['score'])\n",
    "print(test_sent[0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d07bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 2b - Use the bert model, with full scores\n",
    "MODEL_bert = f\"{model_path_bert}\"\n",
    "tokenizer_bert = AutoTokenizer.from_pretrained(MODEL_bert)\n",
    "config_bert = AutoConfig.from_pretrained(MODEL_bert)\n",
    "\n",
    "# PT\n",
    "model_bert = AutoModelForSequenceClassification.from_pretrained(MODEL_bert)\n",
    "# model_bert.save_pretrained(MODEL_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63456b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_bert(sample_text):\n",
    "    encoded_input_bert = tokenizer_bert(sample_text, return_tensors='pt')\n",
    "    output_bert = model_bert(**encoded_input_bert)\n",
    "    scores_bert = output_bert[0][0].detach().numpy()\n",
    "    scores_bert = softmax(scores_bert) #1st score is negative, 2nd score is netural, 3rd score is positive\n",
    "    return scores_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6220f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = scores_bert(sample_text)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c59810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dad604",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    sentiment_xlm = sentiment_task_xlm(data['process_text'][i])\n",
    "    data['label_xlm'][i] = sentiment_xlm[0]['label']\n",
    "#     data['score_xlm'][i] = sentiment_xlm[0]['score']\n",
    "    score_xlm = scores_xlm(data['process_text'][i])\n",
    "    data['negative_xlm'][i] = score_xlm[0]\n",
    "    data['neutral_xlm'][i] = score_xlm[1]\n",
    "    data['positive_xlm'][i] = score_xlm[2]\n",
    "    \n",
    "    sentiment_bert = sentiment_task_bert(data['process_text'][i])\n",
    "    data['label_bert'][i] = sentiment_bert[0]['label']\n",
    "#     data['score_bert'][i] = sentiment_bert[0]['score']\n",
    "    score_bert = scores_bert(data['process_text'][i])\n",
    "    data['negative_bert'][i] = score_bert[0]\n",
    "    data['neutral_bert'][i] = score_bert[1]\n",
    "    data['positive_bert'][i] = score_bert[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ca6e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0283233a",
   "metadata": {},
   "source": [
    "## Step 4 - compare the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e94235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardise(x):\n",
    "    if (x == 'Neutral'):\n",
    "        return 'neutral'\n",
    "    elif (x == 'Bullish'):\n",
    "        return 'positive'\n",
    "    else:\n",
    "        return 'negative'\n",
    "data[\"label_bert\"] = data[\"label_bert\"].apply(standardise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2595b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945214d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['equality'] = data['label_xlm'] == data['label_bert']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aea5bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe380490",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label_xlm'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf241508",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label_bert'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e77e095",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['equality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a422c98a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a164c5fd",
   "metadata": {},
   "source": [
    "## Step 5: Count the total number of labels/scores (positive, negative vs neutral) by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6752e401",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = pd.to_datetime(data.date)\n",
    "data['new_date'] = data['date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f632c9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d67cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = pd.DataFrame(data.groupby(['new_date'])['label_xlm'].value_counts().unstack().fillna(0).reset_index())\n",
    "grouped_data = grouped_data.rename_axis(\"\", axis=\"columns\")\n",
    "\n",
    "grouped_data_bert = pd.DataFrame(data.groupby(['new_date'])['label_bert'].value_counts().unstack().fillna(0).reset_index())\n",
    "grouped_score = pd.DataFrame(data.groupby(['new_date'])[['negative_xlm', 'neutral_xlm', 'positive_xlm','negative_bert', 'neutral_bert', 'positive_bert']].sum().fillna(0).reset_index())\n",
    "\n",
    "grouped_data[['date', 'count_negative_xlm', 'count_neutral_xlm', 'count_positive_xlm']] = grouped_data[['new_date', 'negative', 'neutral', 'positive']]\n",
    "grouped_data[['count_negative_bert', 'count_neutral_bert', 'count_positive_bert']] = grouped_data_bert[['negative', 'neutral', 'positive']]\n",
    "grouped_data[['negative_xlm', 'neutral_xlm', 'positive_xlm','negative_bert', 'neutral_bert', 'positive_bert']] = grouped_score[['negative_xlm', 'neutral_xlm', 'positive_xlm','negative_bert', 'neutral_bert', 'positive_bert']]\n",
    "\n",
    "grouped_data = grouped_data.drop([\"new_date\", 'negative', 'neutral', 'positive'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c4ddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41232498",
   "metadata": {},
   "source": [
    "## Step 6 - Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f8d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = grouped_data['date'][0]\n",
    "start_date_str = datetime.datetime.strftime(start_date, \"%Y-%m-%d\")\n",
    "start_date_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2154ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = grouped_data['date'][len(grouped_data)-1]\n",
    "end_date_str = datetime.datetime.strftime(end_date, \"%Y-%m-%d\")\n",
    "end_date_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df93ef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f\"{start_date_str}_{end_date_str}_twitter_comments.csv\"\n",
    "data.to_csv(f\"~/code/giadapi/crypto/data/processed/{file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fe0d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f\"{start_date_str}_{end_date_str}_twitter_transferlearning.csv\"\n",
    "grouped_data.to_csv(f\"~/code/giadapi/crypto/data/processed/{file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1e8dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
